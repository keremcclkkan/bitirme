{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Algorithm with SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdal\n",
    "import skimage\n",
    "import numpy\n",
    "from PIL import Image\n",
    "ds = gdal.Open('1.tif')\n",
    "width = ds.RasterXSize\n",
    "height = ds.RasterYSize\n",
    "gt = ds.GetGeoTransform()\n",
    "\n",
    "from osgeo import osr\n",
    "srs = osr.SpatialReference()\n",
    "srs.ImportFromWkt(ds.GetProjection())\n",
    "\n",
    "srsLatLong = srs.CloneGeogCS()\n",
    "ct = osr.CoordinateTransformation(srs,srsLatLong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from scipy import misc\n",
    "\n",
    "def template_tracker(link_in='data.mp4', link_out='output_sift.mp4'):\n",
    "    print(\"opening video file...\")\n",
    "    vs = cv2.VideoCapture(link_in)\n",
    "\n",
    "    writer = None\n",
    "    W = None\n",
    "    H = None\n",
    "    totalFrames = 0\n",
    "    check=False\n",
    "    coords=[]\n",
    "    while True:\n",
    "        frame = vs.read()\n",
    "        frame = frame[1]\n",
    "        \n",
    "        if link_in is not None and frame is None:\n",
    "            print(\"end\")\n",
    "            check=True\n",
    "            break\n",
    "        \n",
    "        \n",
    "        \n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "        size = np.array(rgb.shape)\n",
    "        #print(size)\n",
    "        #new_size = tuple((size*0.75).astype(int))\n",
    "        #new_size = (size[:2]*0.75)\n",
    "        #new_size = cv2.normalize(new_size, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "        #rgb = skimage.transform.resize(rgb, new_size)\n",
    "        #rgb = misc.imresize(rgb, 0.75)\n",
    "        rgb = numpy.array(Image.fromarray(rgb).resize((int(0.75 * rgb.shape[1]), int(rgb.shape[0] * 0.75))\n",
    "    ))\n",
    "        #print(np.array(rgb.shape))\n",
    "        \n",
    "        if W is None or H is None:\n",
    "            (H, W) = frame.shape[:2]\n",
    "\n",
    "        if writer is None:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "            writer = cv2.VideoWriter(link_out, fourcc, 30, (2448,1779), True)\n",
    "        # Initiate SIFT detector\n",
    "        sift = cv2.xfeatures2d.SIFT_create()\n",
    "        MIN_MATCH_COUNT = 10\n",
    "        \n",
    "        if totalFrames % 256 == 0:\n",
    "            \n",
    "            img1 = rgb        # queryImage\n",
    "            img2 = plt.imread('1.tif') # trainImage            \n",
    "            \n",
    "            # find the keypoints and descriptors with SIFT\n",
    "            kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "            kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "\n",
    "            FLANN_INDEX_KDTREE = 0\n",
    "            index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 2)\n",
    "            search_params = dict(checks = 2)\n",
    "\n",
    "            flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "            matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "            # store all the good matches as per Lowe's ratio test.\n",
    "            good = []\n",
    "            for m,n in matches:\n",
    "                if m.distance < 0.7*n.distance:\n",
    "                    good.append(m)\n",
    "                    \n",
    "            if len(good)>MIN_MATCH_COUNT:\n",
    "                src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "                dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "\n",
    "                M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "                matchesMask = mask.ravel().tolist()\n",
    "\n",
    "                h,w = img1.shape[:2]\n",
    "                pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "                dst = cv2.perspectiveTransform(pts,M)\n",
    "                points= np.int32(dst)\n",
    "                #print(points)\n",
    "                img2 = cv2.polylines(img2,[np.int32(dst)],True,255,5, cv2.LINE_8)\n",
    "                \n",
    "                M = cv2.moments(points)\n",
    "                \n",
    "                cx = int(M['m10']/M['m00'])\n",
    "                cy = int(M['m01']/M['m00'])\n",
    "                \n",
    "                img2= cv2.circle(img2, (cx, cy), 4, (0, 255, 255), 10)\n",
    "                ax= gt[0] + cx*gt[1] + cy*gt[2]\n",
    "                ay= gt[3] + cx*gt[4] + cy*gt[5]\n",
    "                coord= ct.TransformPoint(ax,ay)\n",
    "                lat= coord[0]\n",
    "                long= coord[1]\n",
    "                #print(long,lat)\n",
    "                \n",
    "            else:\n",
    "                print(\"Not enough matches are found - %d/%d\" % (len(good),MIN_MATCH_COUNT))\n",
    "                matchesMask = None\n",
    "        \n",
    "        draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "                   singlePointColor = None,\n",
    "                   matchesMask = matchesMask, # draw only inliers\n",
    "                   flags = 2)\n",
    "\n",
    "        img3 = cv2.drawMatches(img1,kp1,img2[:,:,:3],kp2,good,None,**draw_params)\n",
    "        img3= cv2.putText(img3, str(lat)+' East', (10,1720), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "        img3= cv2.putText(img3, str(long)+' North', (10,1650), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "        coords.append([lat,long])\n",
    "        \n",
    "        nigg=cv2.cvtColor(img3, cv2.COLOR_RGB2BGR)\n",
    "        #print(nigg.shape)\n",
    "        if writer is not None:\n",
    "            writer.write(nigg)\n",
    "        cv2.namedWindow(\"Frame\", cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(\"Frame\", nigg)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "            \n",
    "        if check:\n",
    "            break\n",
    "            \n",
    "        totalFrames += 1\n",
    "    #print('done')\n",
    "    writer.release()\n",
    "    vs.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return coords\n",
    "    #print(coordss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening video file...\n",
      "end\n",
      "Duration: 0:00:05.592876\n",
      "[[33.642891881458574, 72.99209837629381], [33.642891881458574, 72.99209837629381], [33.642891881458574, 72.99209837629381]]\n",
      "56\n",
      "0:00:00.099873\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "a=template_tracker(link_in='our_data1.mp4', link_out='outputkeremnaz.mp4')\n",
    "end_time = datetime.now()\n",
    "time1=end_time - start_time\n",
    "print('Duration: {}'.format(time1))\n",
    "print(a[:3])\n",
    "print(len(a))\n",
    "\n",
    "print(time1/len(a))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33.642891881458574, 72.99209837629381], [33.642891881458574, 72.99209837629381], [33.642891881458574, 72.99209837629381], [33.642891881458574, 72.99209837629381], [33.642891881458574, 72.99209837629381]]\n"
     ]
    }
   ],
   "source": [
    "print(a[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mb\u001b[49m[:\u001b[38;5;241m5\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'b' is not defined"
     ]
    }
   ],
   "source": [
    "print(b[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
